{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\al_kosa\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\al_kosa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\al_kosa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlight the detected shape of the template on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_shape(img, temp_img, position):\n",
    "    result = img.copy()\n",
    "    result[position[1]: position[1] + temp_img.shape[0],\n",
    "           position[0]: position[0] + temp_img.shape[1]][temp_img != 0] = [255, 0, 0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide template into k segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(template, k):\n",
    "    def neighbours(pix):\n",
    "        x = pix[0]\n",
    "        for y in [pix[1]-1, pix[1]+1]:\n",
    "            yield x, y\n",
    "\n",
    "        y = pix[1]\n",
    "        for x in [pix[0]-1, pix[0]+1]:\n",
    "            yield x, y\n",
    "\n",
    "        for x in [pix[0]-1, pix[0]+1]:\n",
    "            for y in [pix[1]-1, pix[1]+1]:\n",
    "                yield x, y\n",
    "\n",
    "    segment_length = int(np.ceil(template.sum() / 255 / k))\n",
    "    xy_pixels = np.nonzero(template)\n",
    "    pixels = list(zip(xy_pixels[0], xy_pixels[1]))\n",
    "    \n",
    "    segments = []\n",
    "    segment = np.zeros_like(template)\n",
    "    queue = []\n",
    "\n",
    "    old_pixel = pixels[330]  # Will deal with this later\n",
    "    segment[old_pixel[0], old_pixel[1]] = 255\n",
    "    pixels.remove(old_pixel)\n",
    "    \n",
    "    for i in range(1, int(template.sum()/255)):\n",
    "        for x, y in neighbours(old_pixel):\n",
    "            if (x, y) in pixels and (x, y) not in queue:\n",
    "                queue.append((x,y))\n",
    "\n",
    "        pixel = queue.pop(0)\n",
    "        segment[pixel[0], pixel[1]] = 255\n",
    "        pixels.remove(pixel)\n",
    "        old_pixel = pixel\n",
    "\n",
    "        if (i+1) % segment_length == 0:\n",
    "            segments.append(segment)\n",
    "            segment = np.zeros_like(template)\n",
    "    else:\n",
    "        if segment.any():\n",
    "            segments.append(segment)\n",
    "            \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read template image and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = cv2.imread('hand_template.bmp', 0)\n",
    "height, width = temp.shape[::]\n",
    "cap = cv2.VideoCapture('test2.wmv')\n",
    "frame_exists, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_segments = 20\n",
    "n_max = 100\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = get_segments(temp, n_segments)\n",
    "\n",
    "# for segment in segs:\n",
    "#     cv2.imshow('seg', segment)\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each frame:\n",
    "* Convert the frame to gray scale\n",
    "* Apply Canny edge detection\n",
    "* Apply distance transformation\n",
    "* Get the chamfer matching by correlating the transformed frame with the template\n",
    "* Get the location of the maximum matched value\n",
    "* Highlight the shape at that location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "while frame_exists:    \n",
    "    cm = []\n",
    "    max_ind = []\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (7, 7), 1)\n",
    "    edges = cv2.Canny(gray, 50, 200)\n",
    "    dist = cv2.distanceTransform(255 - edges, cv2.DIST_L2, 3)\n",
    "    dist = dist.astype(np.uint8)\n",
    "    \n",
    "    for seg in segments:\n",
    "        cm.append((cv2.matchTemplate(255 - dist, seg, cv2.TM_CCORR) / seg.sum()))\n",
    "        ind = np.unravel_index((-1*cm[-1]).argsort(axis=None), cm[-1].shape)\n",
    "        max_ind.append(np.array([ind[0][:n_max], ind[1][:n_max]]))\n",
    "    \n",
    "    cost_old = alpha * (1 - (cm[0][tuple(max_ind[0])] / 255)) * 10000\n",
    "    idx_tracker = [[x] for x in range(n_max)]\n",
    "    for i in range(1, n_segments):\n",
    "        cost = cost_old[:, None] + alpha * (1 - (cm[i][tuple(max_ind[i])] / 255)) * 10000 + \\\n",
    "               (1 - alpha) * (np.linalg.norm(max_ind[i] - max_ind[i - 1], axis=0))\n",
    "        idx = np.unravel_index((cost).argsort(axis=None), cost.shape)\n",
    "        idx = (idx[0][:n_max], idx[1][:n_max])\n",
    "        cost_old = cost[idx]\n",
    "        idx_tracker1 = idx_tracker.copy()\n",
    "        idx_tracker = [idx_tracker1[x] + [y] for x, y in list(zip(idx[0], idx[1]))]\n",
    "    top_left_idx = idx_tracker[0]\n",
    "\n",
    "    hl_img = frame\n",
    "    for i in range(n_segments):\n",
    "        hl_img = highlight_shape(hl_img, segments[i], (max_ind[i][1][top_left_idx[i]], max_ind[i][0][top_left_idx[i]]))\n",
    "        \n",
    "    cv2.imshow('dt', dist)\n",
    "    cv2.imshow('Edges', edges)\n",
    "    cv2.imshow('Tracking', hl_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_exists, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
